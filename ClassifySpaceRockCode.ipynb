{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 식별 머신을 위한 데이터를 준비한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리를 불러 온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 플로팅 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "# 숫자 처리 라이브러리\n",
    "import numpy as np\n",
    "# 딥러닝을 위한 파이토치 라이브러리\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "# 토치비전 라이브러리\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "# 이미지 처리 라이브러리 (PIL, pillow)\n",
    "from PIL import Image\n",
    "# 주피터 노트북에서 plot이 보이도록 설정\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 디렉토리, 분할 비율, 변환 방법을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터가 있는 디렉토리와 데이터 세트 분할 비율(valid_size)을 정한다.\n",
    "data_dir = './data'\n",
    "valid_size = 0.2\n",
    "\n",
    "# 이미지 데이터를 ResNet50에서 다룰 수 있도록 변환시키는 방법을 정한다. (t_transforms)\n",
    "t_transforms = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 변환 방법을 출력하여 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정한 이미지 데이터 변환 방법을 출력하여 확인한다.\n",
    "print(t_transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로더 함수를 작성한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (연습) trainloader와 testloader를 만들어 본다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 학습 데이터 세트 및 테스트 데이터 세트의 디렉토리 및 변환 방식을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.ImageFolder를 사용해서 학습 데이터(train_data)와 테스트 데이터(test_data)를 만든다.\n",
    "train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "\n",
    "# 학습 데이터의 형식을 확인한다.\n",
    "print(train_data)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터의 길이를 확인한다.\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터세트를 섞기 위해, 우선 인덱스를 만들어 랜덤하게 섞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data 사이즈만큼의 정수값을 갖는 인덱스 리스트(indices)를 만들고 확인한다.\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "print(indices)\n",
    "\n",
    "# 인덱스 리스트를 랜덤하게 섞고 확인한다.\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 분할 비율(valid_size)에 따른 지점의 인덱스 값(split)을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할 비율(valid_size)에 해당하는 인덱스를 계산하고 확인해 본다.\n",
    "split = int(np.floor(num_train * valid_size))\n",
    "print(split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. split을 기준으로 학습 데이터 인덱스 리스트와 테스트 인덱스 리스트로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 인덱스 리스트 및 테스트 인덱스 리스트를 만들고 확인해 본다.\n",
    "\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "print(train_idx)\n",
    "print(test_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 데이터 세트들의 샘플러 및 로더를 만들고 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 샘플링 방식(SubsetRandomSampler)을 지정한다\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# 데이터 로딩을 위한 loader를 만든다. (sampler, 배치 사이즈 등 지정)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "\n",
    "# 학습 loader와 테스트 loader의 class들을 출력하여 확인한다.\n",
    "print(trainloader.dataset.classes)\n",
    "print(testloader.dataset.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드들을 묶어서 load_split_train_test() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드들을 묶어서 load_split_train_test() 함수를 만든다. (입력 : 데이터 디렉토리, 분할 비율) (출력 : 학습 데이터 로더, 테스트 데이터 로더)\n",
    "\n",
    "def load_split_train_test(data_dir, valid_size) :\n",
    "    t_transforms = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "    test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(num_train * valid_size))\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_split_train_test() 함수를 이용하여 trainloader, testloader를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_split_train_test() 함수를 이용하여 trainloader와 testloader를 만들고 확인한다.\n",
    "trainloader, testloader = load_split_train_test(data_dir, 0.2)\n",
    "\n",
    "print(trainloader.dataset.classes)\n",
    "print(testloader.dataset.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 데이터 샘플들을 살펴본다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의의 데이터를 로딩한 후 이미지와 레이블을 반환하는 get_random_images() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_images(num) :\n",
    "\n",
    "    data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "    # loader에서 데이터를 한 개씩 꺼내 주는 iterator를 생성한다.\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의 선택한 이미지를 표시해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 이미지와 레이블을 랜덤하게 가져온다.\n",
    "images, labels = get_random_images(5)\n",
    "# 픽셀 배열을 PIL 형식의 이미지로 변환하고 이미지 크기를 지정한다.\n",
    "to_pil = transforms.ToPILImage()\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# 학습 데이터의 class 리스트를 얻는다.\n",
    "classes = trainloader.dataset.classes\n",
    "# 이미지를 표시하기 위한 설정을 한다.\n",
    "for ii in range(len(images)) :\n",
    "    image = to_pil(images[ii])\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    index = labels[ii].item()\n",
    "    sub.set_title(classes[index])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "# 주피터 노트북에 이미지를 표시한다.\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 모델을 가져와 FCL(Fully Connected Layer)을 수정한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute device를 정한다(CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute device를 정하고 확인한다.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전학습된 ResNet50 모델을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 모델을 pretrained=True로 설정한다.\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 수정 전의 ResNet50 모델을 확인해 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCL을 수정한다.(뉴런 구축, 신경망 연결, FCL의 layer 설정 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 신경망 구축 : 전이학습을 위해 모델의 가중치를 freeze 한다.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# 뉴런들을 연결하여 신경망을 생성한다. (전이학습을 위해 FCL 수정 코드 입력)\n",
    "\n",
    "# 손실함수를 Cross entropy loss 함수로 지정한다.\n",
    "criterion = nn.NLLLoss()\n",
    "# optimizer를 Adam으로 지정한다.\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "# 신경망을 compute device로 보낸다.\n",
    "model.to(device)\n",
    "# 종료 여부를 출력한다.\n",
    "print('done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) FCL을 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델의 FCL을 학습시키고 테스트 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습/검증을 위한 변수를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에폭 및 출력 간격을 설정한다.\n",
    "epochs = 10\n",
    "print_every = 5\n",
    "# 손실 변수들을 초기화 한다.\n",
    "running_loss = 0\n",
    "train_losses, test_losses = [], []\n",
    "# 현재의 학습 단계를 표현하는 steps 변수를 0으로 초기화 한다.\n",
    "steps = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정한 에폭만큼 모델을 학습시키며 검증/평가 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정한 회수만큼 학습 후 테스트 및 평가해 본다.\n",
    "for epoch in range(epochs) :\n",
    "    # 에폭을 count 한다.\n",
    "    epoch += 1\n",
    "    # trainloader로부터 모든 이미지와 레이블을 로드한다.\n",
    "    for inputs, labels in trainloader:\n",
    "        # 학습 단계를 count 하고 출력한다.\n",
    "        steps += 1\n",
    "        print('Training step ', steps)\n",
    "        # 입력 데이터(이미지, 레이블)를 device로 보낸다.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 기존에 학습된 gradient 값을 초기화 한다.(이전에 학습한 값이 영향을 주지 않도록 함)\n",
    "        optimizer.zero_grad()\n",
    "        # 입력 데이터로 순전파를 수행하고 로그 확률을 얻는다.\n",
    "        logps = model.forward(inputs)\n",
    "        # 손실(loss) 값들을 계산한다.\n",
    "        loss = criterion(logps, labels)\n",
    "        # 손실값을 이용하여 gradient를 update한다.\n",
    "        loss.backward()\n",
    "        # gradient를 이용하여 설정된 optimizer로 파라미터를 update한다.\n",
    "        optimizer.step()\n",
    "        # 손실값을 누적/계산한다.\n",
    "        running_loss += loss.item()\n",
    "        # 학습 단계 5회마다 모델을 테스트/평가 한다.\n",
    "        if steps % print_every == 0:\n",
    "            # 손실과 정확도 변수를 초기화 한다.\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            # 모델 평가 모드로 전환한다.\n",
    "            model.eval()\n",
    "            # 모델 평가 시 gradient를 계산하지 않도록 한다.\n",
    "            with torch.no_grad():\n",
    "                # testloader로부터 모든 이미지와 레이블을 로드한다.\n",
    "                for inputs, labels in testloader:\n",
    "                    # 입력 데이터(이미지, 레이블)를 device로 보낸다.\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    # 입력 데이터로 순전파를 수행하고 로그 확률을 얻는다.\n",
    "                    logps = model.forward(inputs)\n",
    "                    # 손실(loss) 값들을 계산한다.\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    # 손실값을 누적시킨다.\n",
    "                    test_loss += batch_loss.item()\n",
    "                    # 로그 확률로부터 진짜 확률값을 계산한다.\n",
    "                    ps = torch.exp(logps)\n",
    "                    # 가장 큰 확률값과 class를 얻는다. (topk : 상위 k번째까지의 값)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    # 레이블들을 top_class와 동일한 형태로 바꾼 후 같은 값들을 얻는다.\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    # equals를 float 텐서로 바꾼 후 평균 정확도를 누적/계산한다.\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            # 학습 손실값과 테스트 손실값을 추가한다.\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "            # 학습 손실값, 테스트 손실값, 테스트 정확도를 출력한다.\n",
    "            print(\"Epoch {}/{}: \".format(epoch, epochs),\n",
    "                  \"Train loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test accuracy: {:.3f}\\n\".format(accuracy/len(testloader))) \n",
    "            # running_loss 값을 초기화 한다.\n",
    "            running_loss = 0\n",
    "            # 모델 학습 모드로 전환한다.\n",
    "            model.train()\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 학습 손실값과 테스트 손실값을 그래프로 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습/테스트 완료된 모델을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추후 로드하여 사용할 수 있도록 학습/테스트 완료된 모델을 저장한다.\n",
    "torch.save(model, 'moonrockmodel.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 완성된 모델을 사용하여 예측한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장한 모델을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 모델을 불러온다.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load('moonrockmodel.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 불러온 모델을 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 예측을 위해 predict_image() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image_tensor = t_transforms(image).float()\n",
    "    input = image_tensor.unsqueeze_(0)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.numpy().argmax()\n",
    "\n",
    "    return index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5개의 이미지를 임의로 가져와 예측해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 모드로 전환한다.\n",
    "model.eval()\n",
    "# 5개의 이미지를 랜덤하게 가져온 후 PIL 형식 변환, 표시할 이미지 크기를 설정한다.\n",
    "to_pil = transforms.ToPILImage()\n",
    "images, labels = get_random_images(5)\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# 데이터의 class 목록을 얻는다.\n",
    "classes = trainloader.dataset.classes\n",
    "\n",
    "# 5개의 이미지에 대해 loop를 수행한다.\n",
    "for ii in range(len(images)):\n",
    "    # 각 이미지에 대해 class를 예측한다.\n",
    "    image = to_pil(images[ii])\n",
    "    index = predict_image(image)\n",
    "    # 이미지 아래에 class를 표시하도록 설정한다.\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    res = labels[ii].item() == index\n",
    "    sub.set_title(classes[index] + ':' + str(res))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "# 레이블이 추가된 이미지를 보여준다.\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "079c03c8cf8035cec5e400826a251aebe7ecdea0e5f7a7c4cb8fb00539067612"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('myenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
